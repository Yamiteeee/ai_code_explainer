import 'dart:io';
import 'package:flutter/foundation.dart'; // For @visibleForTesting and debugPrint
import 'package:google_mlkit_text_recognition/google_mlkit_text_recognition.dart';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'package:image_picker/image_picker.dart';
import 'package:ai_code_explainer/models/explanation_result.dart'; // Import our data model

/// A service class to handle AI-related operations, including text recognition (OCR)
/// and code explanation using Google Gemini API.
class AiService {
  late final ImagePicker _imagePicker;
  late final TextRecognizer _textRecognizer;
  late final GenerativeModel _geminiModel;

  final String _geminiApiKey;

  AiService({required String geminiApiKey}) : _geminiApiKey = geminiApiKey {
    _imagePicker = ImagePicker();
    // Initialize TextRecognizer. The 'script' parameter is removed
    // to avoid the 'Undefined name TextScript' error.
    // It defaults to Latin script, which is suitable for most code.
    _textRecognizer = TextRecognizer(); // MODIFIED LINE
    _geminiModel = GenerativeModel(
      model: 'gemini-2.0-flash',
      apiKey: _geminiApiKey,
    );
  }

  void dispose() {
    _textRecognizer.close();
  }

  Future<XFile?> pickImage(ImageSource source) async {
    try {
      final pickedFile = await _imagePicker.pickImage(source: source);
      return pickedFile;
    } catch (e) {
      debugPrint('AiService: Failed to pick image: $e');
      rethrow;
    }
  }

  @visibleForTesting
  Future<String> recognizeText(XFile image) async {
    final inputImage = InputImage.fromFilePath(image.path);
    try {
      final recognisedText = await _textRecognizer.processImage(inputImage);
      return recognisedText.text;
    } catch (e) {
      debugPrint('AiService: Error recognizing text: $e');
      rethrow;
    }
  }

  @visibleForTesting
  Future<String> explainCode(String codeText) async {
    if (_geminiApiKey == 'YOUR_GEMINI_API_KEY_HERE' || _geminiApiKey.isEmpty) {
      throw Exception('Gemini API Key is not configured. Please set it in your .env file.');
    }

    final prompt = [
      Content.text(
          'Explain the following code snippet. Break it down to describe what each main part or significant line does, like identifying variables, loops, functions, etc. Be concise but informative. If the text provided is clearly not programming code, state that you cannot explain it as code. Present the explanation clearly, perhaps with bullet points or numbered lists if appropriate.\n\n```\n$codeText\n```'),
    ];

    try {
      final response = await _geminiModel.generateContent(prompt);
      return response.text ?? 'No explanation generated by AI.';
    } catch (e) {
      debugPrint('AiService: Error explaining code: $e');
      rethrow;
    }
  }

  Future<ExplanationResult> processCodeImage(ImageSource source) async {
    final XFile? image = await pickImage(source);
    if (image == null) {
      return ExplanationResult.empty();
    }

    final String extractedText = await recognizeText(image);

    if (extractedText.trim().isEmpty) {
      return ExplanationResult(
        extractedCode: 'No readable text recognized from the image. Please ensure the code is clear and well-lit.',
        explanation: 'AI explanation requires text to be recognized first.',
      );
    }

    final String explanation = await explainCode(extractedText);

    return ExplanationResult(
      extractedCode: extractedText,
      explanation: explanation,
    );
  }
}
